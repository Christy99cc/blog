---
title: "【ML】学习曲线"
date: 2020-11-15T15:00:00Z
tags:
- 机器学习
categories: ''

---

> 吴恩达机器学习

学习曲线可以用来判断一个学习算法是否处于偏差、方差问题，或者是两者都有。


![image](https://cdn.sparkling.land/christy/images/DE8B1E9A-B641-4B7B-8A0F-DD117FD95039.jpg)￼
首先，会画出训练误差和交叉验证误差关于训练样本个数m的曲线。

随着训练集样本数量的增多，平均训练误差在增大；
当m很小的时候，会拟合得很好，训练误差将会很小；当m很大的时候，想对每一个样本都拟合得很好就很困难了，训练误差就会比较大。

在交叉验证集上，
当m很小的时候，对于没见过的新样本，泛化程度不会很好，不能很好地适应新样本；当m比较大的时候，才能得到一个很好地拟合数据的假设。

因此，交叉验证集误差和测试集误差都会随着训练集样本容量m的增加而减小；因为使用的数据，越能获得更好的泛化表现，越能拟合出合适的假设h。


### 高偏差情况下
如果假设h出现高偏差问题，
![image](https://cdn.sparkling.land/christy/images/9BA99851-4317-482F-B01D-6038CC9D94A0.jpg)￼

🌰假设函数h如图中所示
如果增大训练集样本容量会发生什么？
训练集样本数量增大，达到或者超过一定值的时候（左图中第二个箭头的位置），还是会得到一条**差不多**的直线（右下图），Jcv会趋于水平（左图）；
训练样本数量很小的时候，训练误差很小；随着训练集样本数量的增多，Jtarin也逐渐增大，一直增大到与Jcv差不多大。

#### 高偏差问题的表现
有很高的验证误差和训练误差，相近

#### 结论
如果一个学习算法有高偏差，随着训练集样本数量的增加，交叉验证误差不会明显地下降了，基本变成水平的了。也就是说，对于高偏差的学习算法，增大样本容量的意义不大。

### 高方差情况下

如果假设h出现高方差问题，
![image](https://cdn.sparkling.land/christy/images/816368DC-FECF-4A5C-AED3-530A13F1E6B5.jpg)￼

🌰假设函数h如图中所示
如果训练集很小（右上图），如果用很高次的多项式来拟合，并且加上一个足够小的正则化参数λ，那么会对这组样本拟合得很好，并且过拟合；**训练误差Jtrain**也会很小。
如果训练集增大（右下图），如果要很高地拟合这组样本，会变得更加困难些；**训练误差Jtrain**也会随着增大，但总的来说训练误差Jtrain还是很小。
在高方差情况下，一直是过拟合，那**交叉验证误差**将会一直都很大。
#### 特点
训练误差与交叉验证误差有一段很大的差距

#### 结论
延长曲线来看，在高方差情况下，增大训练集样本数量是有用的。